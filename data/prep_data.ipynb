{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r data-requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import typing as t\n",
    "\n",
    "# data prep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "\n",
    "# for creating image vector embeddings\n",
    "from PIL import Image\n",
    "from img2vec_pytorch import Img2Vec\n",
    "\n",
    "# for creating semantic (text-based) vector embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# for Redis\n",
    "import redis\n",
    "from redis.commands.search.field import (\n",
    "    NumericField,\n",
    "    TagField,\n",
    "    TextField,\n",
    "    VectorField,\n",
    ")\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.query import Query\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load connection info from .env\n",
    "load_dotenv('../.env')\n",
    "DB_SERVER=os.environ.get('DB_SERVER')\n",
    "DB_NAME=os.environ.get('DB_NAME')\n",
    "DB_USERNAME=os.environ.get('DB_USERNAME')\n",
    "DB_PASSWORD=os.environ.get('DB_PASSWORD')\n",
    "DB_LIMIT=int(os.environ.get('DB_LIMIT'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database, load in data\n",
    "connection_string = f'DRIVER={{ODBC Driver 18 for SQL Server}};SERVER={DB_SERVER};DATABASE={DB_NAME};UID={DB_USERNAME};PWD={DB_PASSWORD};Encrypt=yes;TrustServerCertificate=yes'\n",
    "conn = pyodbc.connect(connection_string) \n",
    "\n",
    "product_query = f'SELECT TOP {DB_LIMIT} [id],[gender],[masterCategory],[subCategory],[articleType],[baseColour],[season],[year],[usage],[productDisplayName] FROM [aidemo].[styles]'\n",
    "\n",
    "df = pd.read_sql_query(product_query, conn)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.info()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"product_text\"] = df.apply(lambda row: f\"name {row['productDisplayName']} category {row['masterCategory']} subcategory {row['subCategory']} color {row['baseColour']} gender {row['gender']}\".lower(), axis=1)\n",
    "df.rename({\"id\":\"product_id\"}, inplace=True, axis=1)\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out one of the texts we will use to create semantic embeddings\n",
    "df[\"product_text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet-18 to create image embeddings\n",
    "img2vec = Img2Vec(cuda=False)\n",
    "\n",
    "# bert variant to create text embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-distilroberta-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def generate_image_vectors(products, image_base_path, batch_size=1000):\n",
    "    output_dict={}\n",
    "\n",
    "    for batch in get_batch(products, batch_size):\n",
    "        product_ids = batch['product_id'].values.tolist()\n",
    "        image_filenames = [image_base_path + \"/\" + str(_id) + \".jpg\" for _id in product_ids]\n",
    "        images=[]\n",
    "        converted=[]\n",
    "\n",
    "        for img_path, _id in zip(image_filenames, product_ids):\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = img.resize((224, 224))\n",
    "                images.append(img)\n",
    "                converted.append(_id)\n",
    "            except:\n",
    "                #unable_to_convert -> skip to the next image\n",
    "                continue\n",
    "\n",
    "        #Generate vectors for all images in this batch\n",
    "        vec_list = img2vec.get_vec(images)\n",
    "\n",
    "        #update the dictionary to be returned\n",
    "        batch_dict= dict(zip(converted, vec_list))\n",
    "        output_dict.update(batch_dict)\n",
    "        print(f\"Processed {str(batch_size)} product images\")\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "def generate_text_vectors(products_df):\n",
    "    text_vectors = {}\n",
    "    # generate text vector\n",
    "    for index, row in products_df.iterrows():\n",
    "        text_vector = model.encode(row[\"product_text\"])\n",
    "        text_vectors[row[\"product_id\"]] = text_vector.astype(np.float32)\n",
    "    \n",
    "    print(f\"Processed {str(len(text_vectors))} product text fields\")\n",
    "    return text_vectors\n",
    "\n",
    "# combine into a single json file\n",
    "def combine_vector_dicts(txt_vectors, img_vectors, products):\n",
    "    product_vectors = []\n",
    "    for _, row in products.iterrows():\n",
    "        try:\n",
    "            _id = row[\"product_id\"]\n",
    "            text_vector = txt_vectors[_id].tolist()\n",
    "            img_vector = img_vectors[_id].tolist()\n",
    "            vector_dict = {\n",
    "                \"text_vector\": text_vector,\n",
    "                \"img_vector\": img_vector,\n",
    "                \"product_id\": _id\n",
    "            }\n",
    "            product_vectors.append(vector_dict)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return product_vectors\n",
    "\n",
    "def write_product_vector_json(vector_dict):\n",
    "    product_vector_json = json.dumps(vector_dict)\n",
    "    with open(\"./product_vectors.json\", \"w\") as f:\n",
    "        f.write(product_vector_json)\n",
    "\n",
    "def write_product_metadata_json(metadata):\n",
    "\n",
    "    products_json = json.dumps(metadata)\n",
    "    with open(\"./product_metadata.json\", \"w\") as f:\n",
    "        f.write(products_json)\n",
    "\n",
    "def create_product_metadata(metadata_df, image_base_path):\n",
    "    products = []\n",
    "    for _, row in metadata_df.iterrows():\n",
    "        product = {\n",
    "            \"product_id\": row[\"product_id\"],\n",
    "            # create a text based representation to create a semantic embedding with\n",
    "            \"product_metadata\": {\n",
    "                \"name\": row[\"productDisplayName\"],\n",
    "                \"gender\": row[\"gender\"],\n",
    "                \"master_category\": row[\"masterCategory\"],\n",
    "                \"sub_category\": row[\"subCategory\"],\n",
    "                \"article_type\": row[\"articleType\"],\n",
    "                \"base_color\": row[\"baseColour\"],\n",
    "                \"season\": row[\"season\"],\n",
    "                \"year\": row[\"year\"],\n",
    "                \"usage\": row[\"usage\"],\n",
    "                \"image_url\": image_base_path + \"/\" + str(row[\"product_id\"]) + \".jpg\",\n",
    "                \"keywords\": '',\n",
    "                \"brand\": '',\n",
    "                \"age_group\": ''\n",
    "            }\n",
    "        }\n",
    "        products.append(product)\n",
    "\n",
    "    return products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process vector and metadata for products\n",
    "data_path = \"../app/vecsim_app/static/images\"\n",
    "images_base_path = \"/images\"\n",
    "\n",
    "image_vectors = generate_image_vectors(df[:DB_LIMIT], data_path, DB_LIMIT)\n",
    "text_vectors = generate_text_vectors(df[:DB_LIMIT])\n",
    "vector_dict = combine_vector_dicts(text_vectors, image_vectors, df)\n",
    "image_dim = [len(i) for i in image_vectors.values()][0]\n",
    "text_dim = [len(i) for i in text_vectors.values()][0]\n",
    "\n",
    "metadata = create_product_metadata(df[:DB_LIMIT], images_base_path)\n",
    "#optional write to file system\n",
    "write_product_metadata_json(metadata)\n",
    "write_product_vector_json(vector_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2308a14f828f4c69c4b8398d837b3e8063b63cb779a5f78af30d2f59d7d7db95"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('vecsim-app')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
